# FLAM - Real-Time Edge Detection Viewer

A real-time edge detection application that captures camera frames on Android, processes them using OpenCV (C++) via JNI, renders with OpenGL ES 2.0, and displays processed frames in a TypeScript web viewer.

## ğŸ“± Features Implemented

### Android Application
- âœ… **Camera Feed Integration**: Uses CameraX API with PreviewView for camera access
- âœ… **Real-time Frame Processing**: Processes each frame using OpenCV C++ via JNI
- âœ… **Edge Detection**: Implements Canny edge detection algorithm
- âœ… **OpenGL ES 2.0 Rendering**: Renders processed frames as textures in real-time
- âœ… **Toggle Raw/Processed View**: Button to switch between raw camera feed and edge-detected output
- âœ… **FPS Counter**: Displays real-time frames per second
- âœ… **Resolution Display**: Shows current frame resolution
- âœ… **Native C++ Integration**: Full JNI bridge for efficient OpenCV processing

### Web Viewer (TypeScript)
- âœ… **Real-time Camera Feed**: Uses local webcam with getUserMedia API
- âœ… **Edge Detection**: JavaScript-based Sobel edge detection running in background
- âœ… **Frame Display**: Canvas-based viewer showing raw camera feed
- âœ… **Frame Statistics**: Real-time display of FPS, resolution, and processing time
- âœ… **Toggle Control**: Button to enable/disable background edge detection
- âœ… **Modular TypeScript Architecture**: Clean, buildable TypeScript project
- âœ… **Responsive Design**: Modern, responsive UI with gradient styling

## ğŸ“¸ Screenshots

### Web Viewer (Working)
![Web Viewer Screenshot](screenshots/web-viewer.png)

The web viewer demonstrates real-time edge detection using your local camera:
- **Real-time Camera Feed**: Displays raw camera feed with edge detection running in background
- **Frame Statistics**: Shows FPS (60), Resolution (640x480), Processing Time (~14.50 ms)
- **Toggle Control**: Button to enable/disable background edge detection processing
- **Modern UI**: Clean interface with gradient styling and responsive design

*Note: Save your screenshot as `screenshots/web-viewer.png` to display it here*

### Android App
![Android App Screenshot](screenshots/android-app.png)
*Note: Screenshots should be added after building and running the app*

## âš™ï¸ Setup Instructions

### Prerequisites

1. **Android Studio** (Arctic Fox or later)
2. **Android NDK** (r23b or later)
3. **OpenCV for Android** (4.8.0 or later)
4. **Node.js** (v18 or later) - for web viewer
5. **TypeScript** (v5.0 or later)

### Android Setup

#### 1. Install Android NDK

```bash
# Via Android Studio SDK Manager
Tools â†’ SDK Manager â†’ SDK Tools â†’ Check "NDK (Side by side)"
```

Or download manually from [Android NDK Downloads](https://developer.android.com/ndk/downloads)

#### 2. Download OpenCV for Android

1. Download OpenCV Android SDK from [OpenCV Releases](https://opencv.org/releases/)
2. Extract the archive
3. Copy the `opencv` folder to `app/src/main/jniLibs/`
4. Update `app/src/main/cpp/CMakeLists.txt` with the correct OpenCV path:

```cmake
set(OpenCV_DIR ${CMAKE_SOURCE_DIR}/../../../opencv/sdk/native/jni)
```

#### 3. Configure Gradle

The project is already configured with:
- NDK support in `app/build.gradle`
- CMake build configuration
- Required dependencies (CameraX, OpenGL)

#### 4. Build and Run

```bash
# Clone the repository
git clone https://github.com/ritik-bit-by-bit/FLAM.git
cd FLAM

# Open in Android Studio
# File â†’ Open â†’ Select project directory

# Build the project
./gradlew build

# Install on device/emulator
./gradlew installDebug
```

### Web Viewer Setup

#### 1. Install Dependencies

```bash
cd web
npm install
```

#### 2. Build TypeScript

```bash
npm run build
```

#### 3. Serve the Web Viewer

```bash
# Option 1: Using npm script
npm run serve

# Option 2: Using any HTTP server
npx http-server . -p 8080
```

Open `http://localhost:8080` in your browser.

## ğŸ§  Architecture Explanation

### Frame Flow

```
Camera (CameraX)
    â†“
ImageAnalysis â†’ FrameProcessor (Java)
    â†“
JNI Bridge
    â†“
opencv_processing.cpp (C++)
    â†“
OpenCV Processing (Canny Edge Detection)
    â†“
JNI Return (int[] pixels)
    â†“
EdgeDetectionRenderer (Java)
    â†“
OpenGL ES 2.0 Texture
    â†“
GLSurfaceView Display
```

### JNI Integration

The JNI bridge connects Java and C++ code:

**Java Side** (`FrameProcessor.java`):
```java
static {
    System.loadLibrary("opencv_processing");
}

public native void processFrame(byte[] yuvData, int width, int height, 
                               int[] outputPixels, boolean enableProcessing);
```

**C++ Side** (`opencv_processing.cpp`):
```cpp
JNIEXPORT void JNICALL
Java_com_flam_edgedetection_FrameProcessor_processFrame(
        JNIEnv *env, jobject thiz,
        jbyteArray yuvData, jint width, jint height,
        jintArray outputPixels, jboolean enableProcessing)
```

The native method:
1. Receives YUV camera frame data
2. Converts to OpenCV Mat format
3. Applies Canny edge detection (if enabled)
4. Converts back to ARGB pixel array
5. Returns processed pixels to Java layer

### OpenGL ES Rendering

The `EdgeDetectionRenderer` class:
- Sets up OpenGL ES 2.0 context
- Creates shaders (vertex and fragment)
- Manages texture for processed frames
- Renders full-screen quad with texture
- Updates texture when new frame arrives

**Shader Pipeline**:
- Vertex shader: Positions quad vertices and texture coordinates
- Fragment shader: Samples texture and outputs to screen

### TypeScript Web Viewer

The web viewer (`web/src/viewer.ts`):
- **EdgeDetectionViewer Class**: Main viewer component
- **Canvas Rendering**: Uses HTML5 Canvas for frame display
- **Statistics Display**: Updates FPS, resolution, processing time
- **Modular Design**: Clean separation of concerns

**Architecture**:
```
index.html
    â†“
index.ts (Entry Point)
    â†“
viewer.ts (EdgeDetectionViewer Class)
    â†“
Canvas API (Rendering)
```

The viewer can receive frames via:
- Base64 encoded images
- File input (for demo)
- WebSocket (future enhancement)
- HTTP endpoint (future enhancement)

## ğŸ“ Project Structure

```
FLAM/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/flam/edgedetection/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MainActivity.java          # Main activity, camera setup
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ FrameProcessor.java        # Frame analysis, JNI bridge
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EdgeDetectionRenderer.java # OpenGL ES renderer
â”‚   â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ opencv_processing.cpp      # OpenCV C++ processing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CMakeLists.txt             # CMake build config
â”‚   â”‚   â”‚   â”œâ”€â”€ res/                           # Android resources
â”‚   â”‚   â”‚   â””â”€â”€ AndroidManifest.xml
â”‚   â”‚   â””â”€â”€ build.gradle                       # App-level Gradle config
â”‚   â””â”€â”€ build.gradle                           # Project-level Gradle config
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ viewer.ts                          # Viewer class
â”‚   â”‚   â””â”€â”€ index.ts                           # Entry point
â”‚   â”œâ”€â”€ index.html                             # Web viewer HTML
â”‚   â”œâ”€â”€ styles.css                             # Styling
â”‚   â”œâ”€â”€ package.json                           # Node dependencies
â”‚   â””â”€â”€ tsconfig.json                          # TypeScript config
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ Dependencies

### Android
- `androidx.camera:camera-core:1.3.1`
- `androidx.camera:camera-camera2:1.3.1`
- `androidx.camera:camera-lifecycle:1.3.1`
- `androidx.camera:camera-view:1.3.1`
- OpenCV Android SDK 4.8.0+

### Web
- TypeScript 5.3.3+
- Node.js 18+

## ğŸš€ Build Commands

### Android
```bash
# Debug build
./gradlew assembleDebug

# Release build
./gradlew assembleRelease

# Install on connected device
./gradlew installDebug
```

### Web
```bash
cd web
npm run build        # Compile TypeScript
npm run serve        # Start HTTP server
```

## ğŸ“ Development Notes

### Performance Optimization
- Frame processing runs on background thread (cameraExecutor)
- OpenGL rendering uses `RENDERMODE_WHEN_DIRTY` for efficiency
- Native C++ processing minimizes JNI overhead
- Texture updates only when new frame arrives

### Future Enhancements
- WebSocket integration for real-time frame streaming
- Multiple filter options (grayscale, invert, blur)
- GLSL shader effects
- Frame recording and export
- Network endpoint for web viewer

## ğŸ“„ License

MIT License

## ğŸ‘¤ Author

Ritik Roshan Yadav

## ğŸ”— Repository

[GitHub Repository](https://github.com/ritik-bit-by-bit/FLAM.git)

---

**Note**: This project was developed as part of a technical assessment for a Software Engineering Intern (R&D) position. The focus is on demonstrating integration skills with Android NDK, OpenCV, OpenGL ES, JNI, and TypeScript.

